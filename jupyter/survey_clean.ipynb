{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Helper-functions\" data-toc-modified-id=\"Helper-functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Helper functions</a></span></li><li><span><a href=\"#Paper-Surveys\" data-toc-modified-id=\"Paper-Surveys-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Paper Surveys</a></span><ul class=\"toc-item\"><li><span><a href=\"#First-paper-wave\" data-toc-modified-id=\"First-paper-wave-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>First paper wave</a></span></li><li><span><a href=\"#Second-paper-wave\" data-toc-modified-id=\"Second-paper-wave-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Second paper wave</a></span></li><li><span><a href=\"#Third-paper-wave\" data-toc-modified-id=\"Third-paper-wave-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Third paper wave</a></span></li></ul></li><li><span><a href=\"#Online-Surveys\" data-toc-modified-id=\"Online-Surveys-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Online Surveys</a></span><ul class=\"toc-item\"><li><span><a href=\"#First-wave\" data-toc-modified-id=\"First-wave-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>First wave</a></span></li><li><span><a href=\"#Second-waves\" data-toc-modified-id=\"Second-waves-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Second waves</a></span></li><li><span><a href=\"#Third-waves\" data-toc-modified-id=\"Third-waves-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Third waves</a></span></li></ul></li><li><span><a href=\"#Clean-up-dataframe\" data-toc-modified-id=\"Clean-up-dataframe-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Clean up dataframe</a></span></li><li><span><a href=\"#Explore-Data\" data-toc-modified-id=\"Explore-Data-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Explore Data</a></span></li><li><span><a href=\"#Export-data\" data-toc-modified-id=\"Export-data-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Export data</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# survey_clean.py\n",
    "This file takes the eight tax rebate survey files and combines them into one CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 100\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_receipt_date(df):\n",
    "    \"\"\"\n",
    "    Returns `df` with a col \"date_receipt\" using\n",
    "    cols `q7` and `q7a`.\n",
    "    \n",
    "    `date_receipt` = 2008-01-01 for unknown dates.\n",
    "    \"\"\"\n",
    "    # create int cols\n",
    "    df['month'] = df.q7.apply(lambda x: int(x) + 3 if x else 1)\n",
    "    df['day'] = df.q7a.apply(lambda x: int(x) - 1 if x and int(x) > 1 else 1)\n",
    "    \n",
    "    # handle out-of-range dates\n",
    "    df.loc[df.month.isin([4, 6]) & (df.day > 30), 'day'] = 30\n",
    "    \n",
    "    # calc date\n",
    "    df['date_receipt'] = df.apply(lambda x: dt.date(2008, x.month if x.month else 1, x.day if x.day else 1), 1)\n",
    "    \n",
    "    # drop cols\n",
    "    df.drop(['month', 'day'], 1, inplace=True)\n",
    "                                  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paper Surveys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First paper wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and clean survey\n",
    "\n",
    "df = pd.read_csv('../data/raw_data/survey/n280532_taxrebate_ppr_wv1.txt', sep = '\\t', header=None, dtype='str')\n",
    "df.columns = ['hhid', 'date', 'q1', 'surveyn_p1_p2', 'q9q11', 'c6', 'c7']\n",
    "df.head()\n",
    "\n",
    "# examine entries with errors\n",
    "display(df.loc[df.c6.notnull(), :])\n",
    "display(df.loc[df.c7.notnull(), :])\n",
    "\n",
    "# Drop all questions after q6 for those with errors\n",
    "# then drop c6 and c7 (because all responses to q6 require follow up)\n",
    "df.loc[df.c6.notnull(), 'q9q11'] = np.NaN\n",
    "df.drop(['c6', 'c7'], 1, inplace=True)\n",
    "df.head()\n",
    "\n",
    "# examine\n",
    "print(len(df))\n",
    "print(len(df.hhid.unique()))\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate surveyn and q9q11\n",
    "df['surveyn'] = df.surveyn_p1_p2.str.slice(stop=6)\n",
    "df['q2'] = df.surveyn_p1_p2.str.slice(start=6, stop=7)\n",
    "df['q3'] = df.surveyn_p1_p2.str.slice(start=7, stop=8)\n",
    "df['q4'] = df.surveyn_p1_p2.str.slice(start=8, stop=9)\n",
    "df['q5'] = df.surveyn_p1_p2.str.slice(start=9, stop=10)\n",
    "df['q6'] = df.surveyn_p1_p2.str.slice(start=10, stop=11)\n",
    "df['q7'] = df.surveyn_p1_p2.str.slice(start=11, stop=12)\n",
    "df['q7a'] = df.surveyn_p1_p2.str.slice(start=12, stop=14)\n",
    "df['q8'] = df.surveyn_p1_p2.str.slice(start=14, stop=15)\n",
    "df['q8a'] = df.surveyn_p1_p2.str.slice(start=15)\n",
    "\n",
    "df['q9'] = df.q9q11.str.slice(stop=1)\n",
    "df['q10'] = df.q9q11.str.slice(start=1, stop=2)\n",
    "df['q11-1'] = df.q9q11.str.slice(start=2, stop=6)\n",
    "df['q11-2'] = df.q9q11.str.slice(start=6, stop=10)\n",
    "df['q11-3'] = df.q9q11.str.slice(start=10, stop=14)\n",
    "df['q11-4'] = df.q9q11.str.slice(start=14, stop=18)\n",
    "df['q11-5'] = df.q9q11.str.slice(start=18)\n",
    "\n",
    "# drop redundant vars\n",
    "df.drop(['surveyn_p1_p2', 'q9q11'], 1, inplace=True)\n",
    "\n",
    "# add var to indicate the hhid answered the paper survey 1\n",
    "df['ans_p1'] = 1\n",
    "\n",
    "# date-ify the date\n",
    "df['date_p1'] = df.date.apply(lambda x: dt.date(int('20' + x[:2]), int(x[2:4]), int(x[4:])))\n",
    "df.drop('date', 1, inplace=True)\n",
    "\n",
    "# get receipt date\n",
    "df = get_receipt_date(df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second paper wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get next paper survey\n",
    "\n",
    "temp = pd.read_csv('../data/raw_data/survey/n280534_taxrebate_ppr_wv2.txt', sep = '\\t', header=None, dtype='str')\n",
    "temp.columns = ['hhid', 'date', 'surveyn', 'p2', 'q9q11', 'c']\n",
    "\n",
    "# drop the one error\n",
    "temp = temp[temp.c.isnull()]\n",
    "\n",
    "# split the relevant questions\n",
    "temp['q6'] = temp.p2.str.slice(stop=1)\n",
    "temp['q7'] = temp.p2.str.slice(start=1, stop=2)\n",
    "temp['q7a'] = temp.p2.str.slice(start=2, stop=4)\n",
    "temp['q8'] = temp.p2.str.slice(start=4, stop=5)\n",
    "temp['q8a'] = temp.p2.str.slice(start=5)\n",
    "\n",
    "temp['q9'] = temp.q9q11.str.slice(stop=1)\n",
    "temp['q10'] = temp.q9q11.str.slice(start=1, stop=2)\n",
    "temp['q11-1'] = temp.q9q11.str.slice(start=2, stop=6)\n",
    "temp['q11-2'] = temp.q9q11.str.slice(start=6, stop=10)\n",
    "temp['q11-3'] = temp.q9q11.str.slice(start=10, stop=14)\n",
    "temp['q11-4'] = temp.q9q11.str.slice(start=14, stop=18)\n",
    "temp['q11-5'] = temp.q9q11.str.slice(start=18)\n",
    "\n",
    "# drop unecessary vars\n",
    "temp.drop(['p2', 'q9q11', 'c'], 1, inplace=True)\n",
    "\n",
    "# add var to indicate the hhid answered the paper survey 1\n",
    "temp['ans_p2'] = 1\n",
    "\n",
    "# date-ify the date\n",
    "temp['date_p2'] = temp.date.apply(lambda x: dt.date(int('20' + x[:2]), int(x[2:4]), int(x[4:])))\n",
    "temp.drop('date', 1, inplace=True)\n",
    "\n",
    "# get receipt date\n",
    "temp = get_receipt_date(temp)\n",
    "\n",
    "print(len(temp))\n",
    "temp.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many obs in df also in temp?\n",
    "temp.loc[temp.hhid.isin(df.loc[df.q6 == \"1\"].hhid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with df\n",
    "# keep most recent survey response for q6 onwards\n",
    "\n",
    "# first, merge q1-q5 and ans_p1 from df into temp\n",
    "temp = pd.merge(temp, df[\\\n",
    "        ['hhid','q1','q2','q3','q4','q5', 'ans_p1', 'date_p1']],\n",
    "        how='left', on ='hhid')\n",
    "\n",
    "# drop all observations from df found in temp\n",
    "df = df[~df.hhid.isin(temp.hhid)]\n",
    "print(len(temp))\n",
    "print(len(df))\n",
    "\n",
    "# concat df with temp\n",
    "df = pd.concat([df, temp], 0, sort=True)\n",
    "df.sort_values('hhid', inplace=True)\n",
    "\n",
    "print(len(df))\n",
    "print(len(df.hhid.unique()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third paper wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# last paper survey\n",
    "temp = pd.read_csv('../data/raw_data/survey/n280599_taxrebate_ppr_wv2.txt', sep = '\\t', header=None, dtype='str')\n",
    "temp.columns = ['hhid', 'date', 'q1', 'surveyn_p1_p2', 'q9q11', 'c6', 'c7']\n",
    "\n",
    "# investigate errors\n",
    "display(temp.loc[(temp.c6.notnull()) | (temp.c7.notnull())])\n",
    "# all have not yet received ESP\n",
    "temp = temp[(temp.c7.isnull()) & (temp.c6.isnull())]\n",
    "\n",
    "# split questions\n",
    "temp['surveyn'] = temp.surveyn_p1_p2.str.slice(stop=6)\n",
    "temp['q2'] = temp.surveyn_p1_p2.str.slice(start=6, stop=7)\n",
    "temp['q3'] = temp.surveyn_p1_p2.str.slice(start=7, stop=8)\n",
    "temp['q4'] = temp.surveyn_p1_p2.str.slice(start=8, stop=9)\n",
    "temp['q5'] = temp.surveyn_p1_p2.str.slice(start=9, stop=10)\n",
    "temp['q6'] = temp.surveyn_p1_p2.str.slice(start=10, stop=11)\n",
    "temp['q7'] = temp.surveyn_p1_p2.str.slice(start=11, stop=12)\n",
    "temp['q7a'] = temp.surveyn_p1_p2.str.slice(start=12, stop=14)\n",
    "temp['q8'] = temp.surveyn_p1_p2.str.slice(start=14, stop=15)\n",
    "temp['q8a'] = temp.surveyn_p1_p2.str.slice(start=15)\n",
    "\n",
    "temp['q9'] = temp.q9q11.str.slice(stop=1)\n",
    "temp['q10'] = temp.q9q11.str.slice(start=1, stop=2)\n",
    "temp['q11-1'] = temp.q9q11.str.slice(start=2, stop=6)\n",
    "temp['q11-2'] = temp.q9q11.str.slice(start=6, stop=10)\n",
    "temp['q11-3'] = temp.q9q11.str.slice(start=10, stop=14)\n",
    "temp['q11-4'] = temp.q9q11.str.slice(start=14, stop=18)\n",
    "temp['q11-5'] = temp.q9q11.str.slice(start=18)\n",
    "\n",
    "temp.drop(['surveyn_p1_p2', 'q9q11', 'c6', 'c7'], 1, inplace=True)\n",
    "\n",
    "# date-ify the date\n",
    "temp['date_p3'] = temp.date.apply(lambda x: dt.date(int('20' + x[:2]), int(x[2:4]), int(x[4:])))\n",
    "temp.drop('date', 1, inplace=True)\n",
    "\n",
    "# get receipt date\n",
    "temp = get_receipt_date(temp)\n",
    "\n",
    "print(len(temp))\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlapping obs?\n",
    "\n",
    "hhids = temp.loc[(temp.q6 == \"1\") & (temp.hhid.isin(df.loc[df.q6 == \"1\"].hhid))].hhid\n",
    "\n",
    "cols = ['hhid', 'q6', 'date_receipt', 'q8a', 'q9', 'q10', 'q11-1']\n",
    "temp2 = pd.merge(temp.loc[temp.hhid.isin(hhids), cols  + ['date_p3']],\n",
    "                 df.loc[df.hhid.isin(hhids), cols + ['date_p1']], how='inner', on='hhid')\n",
    "display(temp2.sort_values('hhid'))\n",
    "\n",
    "# basically the same, keep the OG data where households should not have been sent survey again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with df\n",
    "\n",
    "# remove overlapping records\n",
    "# Gist: remove from temp hhids that have q6 = 1 (these households should not have\n",
    "#  received second survey). Then keep second survey for repeats where follow-up\n",
    "#  is appropriate.\n",
    "print(sum(df.hhid.isin(temp.hhid)))\n",
    "temp = temp.loc[~temp.hhid.isin(df.loc[df.q6 == 1].hhid)]\n",
    "df = df.loc[~df.hhid.isin(temp.hhid)]\n",
    "\n",
    "# concat new obs\n",
    "df = pd.concat([df, temp], 0, sort=True)\n",
    "\n",
    "# how many obs\n",
    "print(len(df))\n",
    "print(len(df.hhid.unique()))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of df as dfpaper\n",
    "df['paper'] = 1\n",
    "dfpaper = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_clean(fname, p2only=False):\n",
    "    \"\"\"\n",
    "    Takes a filename and returns a cleaned dataframe.\n",
    "    \"\"\"  \n",
    "    df = temp = pd.read_csv(f'../data/raw_data/survey/{fname}', sep = '\\t', header=None, dtype='str')\n",
    "    if len(df.columns) == 3:\n",
    "        df.columns = ['c1', 'c2', 'c3']\n",
    "    elif len(df.columns) == 4:\n",
    "        df.columns = ['c0', 'c01', 'c2', 'c3']\n",
    "        df['c1'] = df.c0 + \"0\" + df.c01\n",
    "        df.drop(['c0', 'c01'], 1, inplace=True)\n",
    "    else:\n",
    "        raise ValueError('Not 3 or 4 columns')\n",
    "    \n",
    "    df['hhid'] = df.c1.str.slice(stop=8)\n",
    "    df['date'] = df.c1.str.slice(start=15, stop=21)\n",
    "    df['surveyn'] = fname[1:7]\n",
    "    \n",
    "    if p2only == False:\n",
    "        df['q1'] = df.c1.str.slice(start=27, stop=28)\n",
    "        qlist1 = ['q2', 'q3', 'q4', 'q5', 'q6',\\\n",
    "         'q7', 'q7a', 'q8', 'q8a']\n",
    "        lenlist1 = [0, 1, 2, 3, 4, 5, 6, 8, 9, 13]\n",
    "        lenlist1 = [x+6 for x in lenlist1]\n",
    "    else:\n",
    "        qlist1 = ['q6', 'q7', 'q7a', 'q8', 'q8a']\n",
    "        lenlist1 = [0, 1, 2, 4, 5, 9]\n",
    "        \n",
    "    qlist2 = ['q9', 'q10', 'q11-1', 'q11-2', \\\n",
    "              'q11-3', 'q11-4', 'q11-5']\n",
    "    lenlist2 = [0, 1, 2, 6, 10, 14, 18, 22]\n",
    "    for i in range(len(qlist1)):\n",
    "        df[qlist1[i]] = df.c2.str.slice(start=lenlist1[i], stop=lenlist1[i+1])\n",
    "    for i in range(len(qlist2)):\n",
    "        df[qlist2[i]] = df.c3.str.slice(start=lenlist2[i], stop=lenlist2[i+1])\n",
    "    df = df.drop(['c1', 'c2', 'c3'], 1)\n",
    "    \n",
    "    # date-ify dates\n",
    "    df['date'] = df.date.apply(lambda x: dt.date(int('20' + x[:2]), int(x[2:4]), int(x[4:])))\n",
    "\n",
    "    # get receipt date\n",
    "    df = get_receipt_date(df)\n",
    "    \n",
    "    # print lengths\n",
    "    print(len(df))\n",
    "    print(len(df.hhid.unique()))\n",
    "    print(sum(dfpaper.hhid.isin(df.hhid)))\n",
    "        \n",
    "    return df\n",
    "    \n",
    "# test\n",
    "display(raw_to_clean('n280556_taxrebate_may08_wv1.txt').head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = raw_to_clean('n280556_taxrebate_may08_wv1.txt')\n",
    "temp.rename(columns={'date': 'date_p1'}, inplace=True)\n",
    "temp['ans_p1'] = 2\n",
    "\n",
    "# merge with df \n",
    "df = pd.concat([df, temp], 0, sort=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = raw_to_clean('n280560_taxrebate_may08_wv2.txt', p2only=True)\n",
    "temp.rename(columns={'date': 'date_p2'}, inplace=True)\n",
    "temp['ans_p2'] = 2\n",
    "\n",
    "# merge with df\n",
    "\n",
    "# copy old info for repeat hhids to temp\n",
    "print(sum(temp.hhid.isin(df.hhid)))\n",
    "temp = pd.merge(temp, df[\\\n",
    "        ['hhid','q1','q2','q3','q4','q5']],\n",
    "        how='left', on ='hhid')\n",
    "\n",
    "# remove old hhids\n",
    "df = df[~df.hhid.isin(temp.hhid)]\n",
    "\n",
    "# concat both dfs\n",
    "df = pd.concat([df, temp], 0, sort=True)\n",
    "df.sort_values('hhid', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = raw_to_clean('n280683_taxrebate_may08_wv2.txt', p2only=False)\n",
    "temp.rename(columns={'date': 'date_p2'}, inplace=True)\n",
    "temp['ans_p2'] = 3\n",
    "print(sum(temp.hhid.isin(df.hhid)))\n",
    "\n",
    "# merge with df\n",
    "\n",
    "# remove old hhids\n",
    "df = df[~df.hhid.isin(temp.hhid)]\n",
    "\n",
    "# concat both dfs\n",
    "df = pd.concat([df, temp], 0, sort=True)\n",
    "df.sort_values('hhid', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third waves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = raw_to_clean('n280756_taxrebate_may08_wv3.txt', p2only=False)\n",
    "temp.rename(columns={'date': 'date_p3'}, inplace=True)\n",
    "temp['ans_p3'] = 2\n",
    "print(sum(temp.hhid.isin(df.hhid)))\n",
    "\n",
    "# merge with df\n",
    "\n",
    "# remove old hhids\n",
    "df = df[~df.hhid.isin(temp.hhid)]\n",
    "\n",
    "# concat both dfs\n",
    "df = pd.concat([df, temp], 0, sort=True)\n",
    "df.sort_values('hhid', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = raw_to_clean('n280757_taxrebate_may08_wv3.txt', p2only=True)\n",
    "temp.rename(columns={'date': 'date_p3'}, inplace=True)\n",
    "temp['ans_p3'] = 3\n",
    "\n",
    "# merge with df\n",
    "\n",
    "# copy old info for repeat hhids to temp\n",
    "print(sum(temp.hhid.isin(df.hhid)))\n",
    "temp = pd.merge(temp, df[\\\n",
    "        ['hhid','q1','q2','q3','q4','q5']],\n",
    "        how='left', on ='hhid')\n",
    "\n",
    "# remove old hhids\n",
    "df = df[~df.hhid.isin(temp.hhid)]\n",
    "\n",
    "# concat both dfs\n",
    "df = pd.concat([df, temp], 0, sort=True)\n",
    "df.sort_values('hhid', inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get total observations\n",
    "\n",
    "print(len(df.hhid.unique()))\n",
    "print(len(df))\n",
    "print(df.q6.value_counts())\n",
    "print(df.notnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.surveyn.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only those who receive a check\n",
    "\n",
    "print(df.q6.value_counts())\n",
    "print(sum(df.q6 != \"1\") / len(df))\n",
    "dfc = df.loc[df.q6 == \"1\"]\n",
    "\n",
    "# keep only those who answer both parts of the survey\n",
    "print(sum(dfc.q1.isnull()) / len(df))\n",
    "dfc = dfc.loc[dfc.q1.notnull()]\n",
    "\n",
    "# keep only those who provide a complete date of receipt\n",
    "print(sum(dfc.q7a == \"01\") / len(df))\n",
    "dfc = dfc.loc[dfc.q7a != \"01\"]\n",
    "\n",
    "print(len(dfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missings\n",
    "for c in ['ans_p1', 'ans_p2', 'ans_p3']:\n",
    "    dfc.loc[dfc[c].isnull() | (dfc[c] == ''), c] = 0\n",
    "    dfc[c] = np.array(dfc[c], dtype='int')\n",
    "    \n",
    "# edit missings\n",
    "for c in ['q8a', 'q11-1', 'q11-2', 'q11-3', 'q11-4', 'q11-5']:\n",
    "    dfc.loc[dfc[c].isin(['dnk', '']), c] = 0\n",
    "dfc.loc[dfc.paper.isnull(), 'paper'] = 0\n",
    "\n",
    "# int types\n",
    "for c in ['q1', 'q10', 'q11-1', 'q11-2', 'q11-3', 'q11-4',\n",
    "       'q11-5', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q7a', 'q8', 'q8a', 'q9',\n",
    "       'surveyn', 'hhid', 'paper']:\n",
    "    print(c)\n",
    "    dfc[c] = np.array(dfc[c], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make same cuts as Broda & Parker 2014\n",
    "print(len(dfc))\n",
    "\n",
    "# already dropped households reporting not receiving an ESP and no date\n",
    "\n",
    "# First, drop reporting receipt date after answering earlier survey.\n",
    "#  Allow grace period in case survey results recording arriving later.\n",
    "\n",
    "# case1: date_receipt before date_p1 and one of the two following surveys answered\n",
    "grace_period = dt.timedelta(days=2)\n",
    "dfc['dropx'] = np.array((dfc.date_receipt + grace_period < dfc.date_p1) & \n",
    "                               dfc.date_p1.notnull() & \n",
    "                            ((dfc.date_p2.notnull() & \n",
    "                               (dfc.ans_p3 == 0)) |\n",
    "                            dfc.date_p3.notnull()), dtype='int')\n",
    "print(dfc.dropx.value_counts())\n",
    "# case2: date_receipt before date_p2 and date_p3 answered\n",
    "dfc['dropx'] += np.array((dfc.date_receipt + grace_period < dfc.date_p2) & \n",
    "                               dfc.date_p2.notnull() & \n",
    "                               dfc.date_p3.notnull(), dtype='int')\n",
    "print(dfc.dropx.value_counts())\n",
    "\n",
    "# Next, drop those reporting receipt after submitting survey\n",
    "dfc['date_final_survey'] = dfc.date_p3\n",
    "dfc.loc[dfc.date_final_survey.isnull(), 'date_final_survey'] = dfc.loc[dfc.date_final_survey.isnull()].date_p2\n",
    "dfc.loc[dfc.date_final_survey.isnull(), 'date_final_survey'] = dfc.loc[dfc.date_final_survey.isnull()].date_p1\n",
    "print(sum(dfc.date_final_survey.isnull()))\n",
    "dfc['dropx'] += np.array((dfc.date_receipt - grace_period > dfc.date_final_survey), dtype='int')\n",
    "print(dfc.dropx.value_counts())\n",
    "\n",
    "# Next, drop those reporting receiving direct deposit or mail outside of acceptable range\n",
    "# For mail, allow extra 7 days for mail time\n",
    "# Mail\n",
    "grace_period = dt.timedelta(days=7)\n",
    "start_date =  dt.date(2008, 5, 16)\n",
    "end_date = dt.date(2008, 7, 11)\n",
    "dfc['dropx'] += np.array(~(dfc.date_receipt.between(start_date - grace_period, end_date + 2 * grace_period)) &\n",
    "                          (dfc.q8 == 2), dtype='int')\n",
    "print(dfc.dropx.value_counts())\n",
    "\n",
    "# Direct deposit\n",
    "start_date =  dt.date(2008, 4, 28)  # direct deposit\n",
    "end_date = dt.date(2008, 5, 16)  # direct deposit\n",
    "dfc['dropx'] += np.array(~(dfc.date_receipt.between(start_date - grace_period, end_date + 1 * grace_period)) &\n",
    "                          (dfc.q8 != 2), dtype='int')\n",
    "print(dfc.dropx.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop where necessary\n",
    "\n",
    "dfc = dfc.loc[dfc.dropx == 0]\n",
    "dfc.drop('dropx', 1, inplace=True)\n",
    "dfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks\n",
    "for i in ['q1', 'q2', 'q3', 'q4', 'q5', 'q6',\\\n",
    "         'q7', 'q7a', 'q8', 'q9', 'q10']:\n",
    "    print('\\n' + i)\n",
    "    display(dfc.loc[:, i].value_counts().sort_index())\n",
    "    \n",
    "for i in ['q8a', 'q11-1', 'q11-2', 'q11-3', 'q11-4', 'q11-5']:\n",
    "    print('\\n' + i)\n",
    "    display(dfc.loc[:, i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(dfc.q3, dfc.q4, margins=True)\n",
    "# q3 = 1 -> spend today\n",
    "# q3 = 2 -> save\n",
    "# q4 = 1 -> 2 months saved\n",
    "# q4 = 2 -> <2 months saved\n",
    "\n",
    "# 1 - 2 -> hand to mouth\n",
    "# 2 - 1 -> successful planners\n",
    "# 2 - 2 -> liars (unsuccessful planners)\n",
    "# 1 - 1 -> retirees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q6 == 1 -> received rebate\n",
    "display(dfc.q6.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q7 = month received\n",
    "display(dfc.q7.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q7a = day received\n",
    "# off by 1, 01 == IDK\n",
    "display(dfc.q7a.value_counts(dropna=False).sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# q8a = rebate amount\n",
    "display(dfc.q8a.value_counts().head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q9 = amount expecting\n",
    "dfc.q9.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.to_csv('../data/gen_data/survey_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "208.6px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
